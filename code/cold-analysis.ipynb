{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bd6c64",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea4dbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### basic imports, read in raw data file\n",
    "import csv, statistics, random, os\n",
    "import nltk\n",
    "from nltk import agreement\n",
    "\n",
    "data_2016 = []\n",
    "data_2035 = []\n",
    "data_2016_models = []\n",
    "\n",
    "with open(os.path.abspath('../data/cold-2016-majVote-fineGrained.tsv'),encoding='utf8') as infile:\n",
    "    csvreader = csv.reader(infile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        data_2016.append(row)\n",
    "        \n",
    "with open(os.path.abspath('../data/cold-2035-needs-reformat.tsv'),encoding='utf8') as f : \n",
    "    text = f.read()\n",
    "data_2035 = text.split('\\n')\n",
    "data_2035 = [line.split('\\t') for line in data_2035]\n",
    "\n",
    "with open(os.path.abspath('../data/cold-2016-majVote-withResults.tsv'),encoding='utf8') as infile:\n",
    "    csvreader = csv.reader(infile, delimiter=\"\\t\")\n",
    "    for row in csvreader:\n",
    "        data_2016_models.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27cf018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ID', 'DataSet', 'Text', 'Off', 'Slur', 'Nom', 'Dist', 'Cat'], ['C-11', 'C', \"I don't think of you as a Mexican\", 'Y', 'N', 'N', 'Y', 'offDist']]\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "### check the data/header line\n",
    "print(data_2016[:2])\n",
    "print(len(data_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ae1639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ID', 'DataSet', 'Text', 'Off1', 'Off2', 'Off3', 'Slur1', 'Slur2', 'Slur3', 'Nom1', 'Nom2', 'Nom3', 'Dist1', 'Dist2', 'Dist3'], ['D-5', 'D', 'You’re black? You don’t sound like you’re black', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'Y', 'N', 'N', 'N', 'N', 'Y']]\n",
      "2036\n"
     ]
    }
   ],
   "source": [
    "### check the data/header line\n",
    "print(data_2035[:2])\n",
    "print(len(data_2035))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "86c7a585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ID', 'DataSet', 'Text', 'Off', 'Slur', 'Nom', 'Dist', 'Cat', 'Mod1', 'Mod2', 'Mod3', 'Mod4'], ['WH-13857342i', 'WH', '@wetsprocket but given that these people seem to not understand the difference between charity and NPO, why bother giving them my time?', 'N', 'N', 'N', 'Y', 'nonDist', 'NOT', 'NOT', 'NOT', 'NOT'], ['D-7798', 'D', \"All da white folk off twitter yet? Da colored tweet at night while y'all sleep cuz you gotta woyke tomorrow.\", 'N', 'N', 'N', 'Y', 'nonDist', 'NOT', 'NOT', 'NOT', 'NOT'], ['D-7890', 'D', 'RT @SwayHasAnswers: Twerking is ghetto until White people do it. Hip Hop culture is violent & dangerous until they want to profit of it. ht.', 'N', 'N', 'N', 'Y', 'nonDist', 'HATE', 'HOF', 'HOF', 'NOT'], ['D-16788', 'D', 'not all black girls are ghetto though', 'N', 'N', 'N', 'Y', 'nonDist', 'NOT', 'NOT', 'HOF', 'TOX'], ['D-18631', 'D', 'RT @ZephTheGreat: Not all black girls are ghetto .', 'N', 'N', 'N', 'Y', 'nonDist', 'NOT', 'NOT', 'HOF', 'TOX'], ['D-23348a', 'D', '@SaltyBlackBroad ma\\'am ...Did you clear that tweet with the @NAACP ? Careful they may brand you \"race traitor\" for the nerve of thinking&#9786;&#65039;', 'N', 'N', 'N', 'Y', 'nonDist', 'NOT', 'HOF', 'HOF', 'TOX'], ['M-22', 'M', 'I prefer to include gays in the definition of marriage.', 'N', 'N', 'Y', 'N', 'nonNom', 'NOT', 'NOT', 'NOT', 'NOT'], ['M-23', 'M', 'I actually like the term marriage that includes gays over gay marriage.', 'N', 'N', 'Y', 'N', 'nonNom', 'NOT', 'NOT', 'NOT', 'NOT'], ['M-24', 'M', 'Thanks for that first! Like most of us, I still have a open wound caused by a female.', 'N', 'N', 'Y', 'N', 'nonNom', 'NOT', 'NOT', 'NOT', 'NOT']]\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "### check the data/header line\n",
    "print(data_2016_models[:10])\n",
    "print(len(data_2016_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0f802",
   "metadata": {},
   "source": [
    "# 4 COLD: The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a19ffd",
   "metadata": {},
   "source": [
    "## 4.2 Annotation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39ef1c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offensive: 952 (maj Y), 1064 (maj N)\n",
      "contains slur: 1012 (maj Y), 1004 (maj N)\n",
      "adj. nom.: 500 (maj Y), 1516 (maj N)\n",
      "distancing: 89 (maj Y), 1927 (maj N)\n"
     ]
    }
   ],
   "source": [
    "#Distribution of Labels in the COLD Corpus\n",
    "majorities = [0,0,0,0]\n",
    "for line in data_2016:\n",
    "    line = line[3:7]\n",
    "    for i in range(len(line)):\n",
    "        if line[i] == \"Y\":\n",
    "            majorities[i] += 1\n",
    "\n",
    "print(\"offensive: \" +str(majorities[0])+ \" (maj Y), \" + str((len(data_2016[1:]) - majorities[0])) + \" (maj N)\")\n",
    "print(\"contains slur: \" +str(majorities[1])+ \" (maj Y), \" + str((len(data_2016[1:]) - majorities[1])) + \" (maj N)\")\n",
    "print(\"adj. nom.: \" +str(majorities[2])+ \" (maj Y), \" + str((len(data_2016[1:]) - majorities[2])) + \" (maj N)\")\n",
    "print(\"distancing: \" +str(majorities[3])+ \" (maj Y), \" + str((len(data_2016[1:]) - majorities[3])) + \" (maj N)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6edbae",
   "metadata": {},
   "source": [
    "## 4.3 Inter-annotator agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28134508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agreement for tweets with 3 ratings (num=2035):\n",
      "\tFleiss for Off: 0.6115018165253099\tAlpha for Off: 0.6109233389328186\n",
      "\tFleiss for Slur: 0.37906614983869746\tAlpha for Slur: 0.37878069251244306\n",
      "\tFleiss for AdjNom: 0.434055366807919\tAlpha for AdjNom: 0.43381219056894726\n",
      "\tFleiss for Dist: 0.756388204609194\tAlpha for Dist: 0.7562809480396007\n"
     ]
    }
   ],
   "source": [
    "for r in [(data_2035[1:],3)]:\n",
    "    raters = r[1]\n",
    "    allOff = []\n",
    "    allSlur = []\n",
    "    allNom = []\n",
    "    allDist = []\n",
    "    for line in r[0]:\n",
    "        id = line[0]\n",
    "        allOff += [[str(i), id, line[3+i]] for i in range(raters)]\n",
    "        allSlur += [[str(i), id, line[4+i]] for i in range(raters)]\n",
    "        allNom += [[str(i), id, line[5+i]] for i in range(raters)]\n",
    "        allDist += [[str(i), id, line[6+i]] for i in range(raters)]\n",
    "    offTask = agreement.AnnotationTask(data=allOff)\n",
    "    slurTask = agreement.AnnotationTask(data=allSlur)\n",
    "    nomTask = agreement.AnnotationTask(data=allNom)\n",
    "    distTask = agreement.AnnotationTask(data=allDist)\n",
    "\n",
    "    print()\n",
    "    print(\"Agreement for tweets with \"+str(raters)+\" ratings (num=\"+str(len(r[0]))+\"):\")\n",
    "    print(\"\\tFleiss for Off: \"+str(offTask.multi_kappa())+\"\\tAlpha for Off: \"+str(offTask.alpha()))\n",
    "    print(\"\\tFleiss for Slur: \"+str(slurTask.multi_kappa())+\"\\tAlpha for Slur: \"+str(slurTask.alpha()))\n",
    "    print(\"\\tFleiss for AdjNom: \"+str(nomTask.multi_kappa())+\"\\tAlpha for AdjNom: \"+str(nomTask.alpha()))\n",
    "    print(\"\\tFleiss for Dist: \"+str(distTask.multi_kappa())+\"\\tAlpha for Dist: \"+str(distTask.alpha()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776f5e23",
   "metadata": {},
   "source": [
    "## 4.4 Data set details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0393327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off with slur: 620\n",
      "off with nom: 201\n",
      "off with distancing: 19\n",
      "off with both: 31\n",
      "off, no cues: 81\n",
      "total off: 952\n",
      "reclaimed slur: 392\n",
      "non-off with nom: 141\n",
      "non-off with distancing: 6\n",
      "non-off with both: 0\n",
      "non-off, no cues: 525\n",
      "total non-off: 1064\n"
     ]
    }
   ],
   "source": [
    "#number of instances per fine-grained categroy, based on majority vote of three annotators\n",
    "cats = {'offSlur': 0, 'offBoth': 0, 'offNom' :0, 'offDist':0, 'offOther':0, 'reclaimed':0, 'nonBoth':0,'nonNom':0,'nonDist':0, 'nonNone':0}\n",
    "for line in data_2016[1:]:\n",
    "    cats[line[7]] +=1\n",
    "    \n",
    "print(\"off with slur: \" + str(cats[\"offSlur\"]))\n",
    "print(\"off with nom: \" + str(cats[\"offNom\"]))\n",
    "print(\"off with distancing: \" + str(cats[\"offDist\"]))\n",
    "print(\"off with both: \" + str(cats[\"offBoth\"]))\n",
    "print(\"off, no cues: \" + str(cats[\"offOther\"]))\n",
    "print(\"total off: \" + str(sum([cats[\"offSlur\"], cats[\"offNom\"], cats[\"offDist\"],cats[\"offBoth\"],cats[\"offOther\"]])))\n",
    "\n",
    "print(\"reclaimed slur: \" + str(cats[\"reclaimed\"]))\n",
    "print(\"non-off with nom: \" + str(cats[\"nonNom\"]))\n",
    "print(\"non-off with distancing: \" + str(cats[\"nonDist\"]))\n",
    "print(\"non-off with both: \" + str(cats[\"nonBoth\"]))\n",
    "print(\"non-off, no cues: \" + str(cats[\"nonNone\"]))\n",
    "print(\"total non-off: \" + str(sum([cats[\"reclaimed\"], cats[\"nonNom\"], cats[\"nonDist\"],cats[\"nonBoth\"],cats[\"nonNone\"]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ec80b",
   "metadata": {},
   "source": [
    "# 5. Using Cold for Diagnostic evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109090ce",
   "metadata": {},
   "source": [
    "## 5.3 Diagnosis of performance on fine-grained categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cfced341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResultsBinary(pairs, dicto):\n",
    "    counts = 0\n",
    "    for p in pairs:\n",
    "        cat = p[0]\n",
    "        label = p[1]\n",
    "        if label == 'NOT':\n",
    "            dicto[cat][1] += 1\n",
    "            counts += 1\n",
    "        elif label == 'HOF' or label == 'OFF' or label == 'TOX' or label=='HATE' or label=='OFFN' or label == 'PRFN':\n",
    "            dicto[cat][0] += 1\n",
    "            counts += 1\n",
    "        else:\n",
    "            print(\"label error:\", label)\n",
    "            input(\"okay? \")\n",
    "    print(dicto)\n",
    "    \n",
    "    \n",
    "def getResultsHasoc(pairs, dicto):\n",
    "    counts = 0\n",
    "    for p in pairs:\n",
    "        cat = p[0]\n",
    "        label = p[1]\n",
    "        #print(cat, label)\n",
    "        if label == 'HATE':\n",
    "            dicto[cat][0] += 1\n",
    "            counts += 1\n",
    "        elif label ==  'OFFN' or label == 'OFF':\n",
    "            dicto[cat][1] += 1\n",
    "            counts += 1\n",
    "        elif label == 'PRFN':\n",
    "            dicto[cat][2] += 1\n",
    "            counts += 1\n",
    "        elif label == 'NOT':\n",
    "            dicto[cat][3] += 1\n",
    "            counts += 1\n",
    "        else:\n",
    "            print(\"label error:\", label)\n",
    "            input(\"okay? \")\n",
    "    print(dicto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8c87a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc = []\n",
    "hasoc_binary = []\n",
    "olid_2019 = []\n",
    "toxic = []\n",
    "olid_2020 = []\n",
    "\n",
    "for line in data_2016_models[1:]:\n",
    "    cat = line[7]\n",
    "    hasoc.append((cat, line[8]))\n",
    "    hasoc_binary.append((cat, line[9]))\n",
    "    olid_2019.append((cat, line[10]))\n",
    "    olid_2020.append((cat, line[10]))\n",
    "    toxic.append((cat, line[11]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a9dbdec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nonDist', 'NOT'), ('nonDist', 'NOT'), ('nonDist', 'NOT'), ('nonDist', 'TOX'), ('nonDist', 'TOX'), ('nonDist', 'TOX'), ('nonNom', 'NOT'), ('nonNom', 'NOT'), ('nonNom', 'NOT'), ('nonNom', 'NOT')]\n"
     ]
    }
   ],
   "source": [
    "print(toxic[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f0e0a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasocDict = {}\n",
    "hasoc_binaryDict = {}\n",
    "olid_2019_Dict = {}\n",
    "toxicDict = {}\n",
    "olid_2020_Dict = {}\n",
    "\n",
    "for k in cats.keys():\n",
    "    hasocDict[k] = [0,0,0,0]\n",
    "    hasoc_binaryDict[k] = [0,0]\n",
    "    olid_2019_Dict[k] = [0,0]\n",
    "    toxicDict[k] = [0,0]\n",
    "    olid_2020_Dict[k] = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "26800bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running full hasoc\n",
      "{'offSlur': [30, 129, 287, 174], 'offBoth': [5, 4, 3, 19], 'offNom': [27, 19, 25, 130], 'offDist': [6, 5, 2, 6], 'offOther': [12, 23, 12, 34], 'reclaimed': [3, 14, 253, 122], 'nonBoth': [0, 0, 0, 0], 'nonNom': [9, 8, 10, 114], 'nonDist': [1, 0, 0, 5], 'nonNone': [20, 18, 24, 463]}\n",
      "\n",
      "\n",
      "running hasoc binary\n",
      "{'offSlur': [480, 140], 'offBoth': [14, 17], 'offNom': [81, 120], 'offDist': [13, 6], 'offOther': [60, 21], 'reclaimed': [308, 84], 'nonBoth': [0, 0], 'nonNom': [48, 93], 'nonDist': [2, 4], 'nonNone': [117, 408]}\n",
      "\n",
      "\n",
      "running olid_2019\n",
      "{'offSlur': [529, 91], 'offBoth': [23, 8], 'offNom': [128, 73], 'offDist': [13, 6], 'offOther': [64, 17], 'reclaimed': [310, 82], 'nonBoth': [0, 0], 'nonNom': [61, 80], 'nonDist': [4, 2], 'nonNone': [142, 383]}\n",
      "\n",
      "\n",
      "running toxic\n",
      "{'offSlur': [547, 73], 'offBoth': [7, 24], 'offNom': [80, 121], 'offDist': [12, 7], 'offOther': [62, 19], 'reclaimed': [337, 55], 'nonBoth': [0, 0], 'nonNom': [40, 101], 'nonDist': [3, 3], 'nonNone': [104, 421]}\n"
     ]
    }
   ],
   "source": [
    "print(\"running full hasoc\")\n",
    "getResultsHasoc(hasoc, hasocDict)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"running hasoc binary\")\n",
    "getResultsBinary(hasoc_binary, hasoc_binaryDict)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"running olid_2019\")\n",
    "getResultsBinary(olid_2019, olid_2019_Dict)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"running toxic\")\n",
    "getResultsBinary(toxic, toxicDict)\n",
    "\n",
    "#we don't have these results\n",
    "#print(\"running olid_2020\")\n",
    "#getResultsBinary(olid_2020, olid_2020_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2fdb5",
   "metadata": {},
   "source": [
    "### Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bbc57536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_binary(dicto):\n",
    "    # Print the names of the columns.\n",
    "    print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format('TYPE', 'OFF', 'NON','|','OFF%', 'NON%'))\n",
    " \n",
    "    # print each data item.\n",
    "    for key, value in dicto.items():\n",
    "        off, noff = value\n",
    "        offp= 0\n",
    "        noffp = 0\n",
    "        if (off + noff):\n",
    "            offp = round(off/(off+noff),3)\n",
    "            noffp = round(noff/(off+noff),3)\n",
    "        print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(key, off, noff,'|',offp,noffp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e5d25076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasoc Binary\n",
      "TYPE       OFF        NON        |          OFF%       NON%      \n",
      "offSlur    480        140        |          0.774      0.226     \n",
      "offBoth    14         17         |          0.452      0.548     \n",
      "offNom     81         120        |          0.403      0.597     \n",
      "offDist    13         6          |          0.684      0.316     \n",
      "offOther   60         21         |          0.741      0.259     \n",
      "reclaimed  308        84         |          0.786      0.214     \n",
      "nonBoth    0          0          |          0          0         \n",
      "nonNom     48         93         |          0.34       0.66      \n",
      "nonDist    2          4          |          0.333      0.667     \n",
      "nonNone    117        408        |          0.223      0.777     \n"
     ]
    }
   ],
   "source": [
    "print(\"Hasoc Binary\")\n",
    "print_dict_binary(hasoc_binaryDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "56182eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLID-19\n",
      "TYPE       OFF        NON        |          OFF%       NON%      \n",
      "offSlur    529        91         |          0.853      0.147     \n",
      "offBoth    23         8          |          0.742      0.258     \n",
      "offNom     128        73         |          0.637      0.363     \n",
      "offDist    13         6          |          0.684      0.316     \n",
      "offOther   64         17         |          0.79       0.21      \n",
      "reclaimed  310        82         |          0.791      0.209     \n",
      "nonBoth    0          0          |          0          0         \n",
      "nonNom     61         80         |          0.433      0.567     \n",
      "nonDist    4          2          |          0.667      0.333     \n",
      "nonNone    142        383        |          0.27       0.73      \n"
     ]
    }
   ],
   "source": [
    "print(\"OLID-19\")\n",
    "print_dict_binary(olid_2019_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "35e3db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic\n",
      "TYPE       OFF        NON        |          OFF%       NON%      \n",
      "offSlur    547        73         |          0.882      0.118     \n",
      "offBoth    7          24         |          0.226      0.774     \n",
      "offNom     80         121        |          0.398      0.602     \n",
      "offDist    12         7          |          0.632      0.368     \n",
      "offOther   62         19         |          0.765      0.235     \n",
      "reclaimed  337        55         |          0.86       0.14      \n",
      "nonBoth    0          0          |          0          0         \n",
      "nonNom     40         101        |          0.284      0.716     \n",
      "nonDist    3          3          |          0.5        0.5       \n",
      "nonNone    104        421        |          0.198      0.802     \n"
     ]
    }
   ],
   "source": [
    "print(\"Toxic\")\n",
    "print_dict_binary(toxicDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca6689",
   "metadata": {},
   "source": [
    "### Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "78caf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_multi(dicto):\n",
    "    # Print the names of the columns.\n",
    "    print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format('TYPE', 'TOTAL', 'HATE','OFF', 'PROF','NOT','|', 'HATE%','OFF%','PROF%','NOT%'))\n",
    " \n",
    "    # print each data item.\n",
    "    for key, value in dicto.items():\n",
    "        hate,off,prof,noff = value\n",
    "        hatep= 0\n",
    "        offp=0\n",
    "        profp=0\n",
    "        noffp = 0\n",
    "        total = off + noff + hate+prof\n",
    "        if total:\n",
    "            offp = round(off/total,3)\n",
    "            noffp = round(noff/total,3)\n",
    "            hatep = round(hate/total,3)\n",
    "            profp = round(prof/total,3)\n",
    "        print (\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(key,total,hate, off,prof, noff,'|', hatep,offp,profp,noffp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9baf1f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HASOC-multi\n",
      "TYPE       TOTAL      HATE       OFF        PROF       NOT        |          HATE%      OFF%       PROF%      NOT%      \n",
      "offSlur    620        30         129        287        174        |          0.048      0.208      0.463      0.281     \n",
      "offBoth    31         5          4          3          19         |          0.161      0.129      0.097      0.613     \n",
      "offNom     201        27         19         25         130        |          0.134      0.095      0.124      0.647     \n",
      "offDist    19         6          5          2          6          |          0.316      0.263      0.105      0.316     \n",
      "offOther   81         12         23         12         34         |          0.148      0.284      0.148      0.42      \n",
      "reclaimed  392        3          14         253        122        |          0.008      0.036      0.645      0.311     \n",
      "nonBoth    0          0          0          0          0          |          0          0          0          0         \n",
      "nonNom     141        9          8          10         114        |          0.064      0.057      0.071      0.809     \n",
      "nonDist    6          1          0          0          5          |          0.167      0.0        0.0        0.833     \n",
      "nonNone    525        20         18         24         463        |          0.038      0.034      0.046      0.882     \n"
     ]
    }
   ],
   "source": [
    "print(\"HASOC-multi\")\n",
    "print_dict_multi(hasocDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
